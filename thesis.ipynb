{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bce3d76-4271-4567-b0bb-832844206bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h0/pjxkfbkd0jn4b1ngbzy6_d3c0000gn/T/ipykernel_33734/2947326146.py:1: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses\n",
      "  import imp\n",
      "/Users/diganto/opt/anaconda3/envs/tf/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization, GlobalAveragePooling2D, InputLayer, LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import shutil\n",
    "import glob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6354fc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "2087\n",
      "Brain Tumor\n",
      "2513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('Healthy', 2087), ('Brain Tumor', 2513)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = \"/Users/diganto/Data/Thesis/Brain Tumor Data Set\"\n",
    "number_of_images = {}\n",
    "\n",
    "for dir in os.listdir(ROOT_DIR):\n",
    "    print(dir)\n",
    "    print(len(os.listdir(os.path.join(ROOT_DIR, dir))))\n",
    "    number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR, dir)))\n",
    "\n",
    "number_of_images.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def dataFolder(p, split):\n",
    "    \n",
    "    if not os.path.exists(\"./dataset/\" + p):\n",
    "        os.makedirs(\"./dataset/\" + p)\n",
    "    \n",
    "    for dir in os.listdir(ROOT_DIR):\n",
    "        os.makedirs(\"./dataset/\"+ p + \"/\" + dir)\n",
    "        \n",
    "        for img in np.random.choice(a = os.listdir(os.path.join(ROOT_DIR, dir)), \n",
    "                                    size=(math.floor(split*number_of_images[dir])-5) ,\n",
    "                                    replace = False):\n",
    "            \n",
    "            O = os.path.join(ROOT_DIR, dir, img) #only complete path\n",
    "            D = os.path.join(\"./dataset/\"+p, dir) #only complete path\n",
    "            shutil.copy(O,D)\n",
    "            #os.remove(O)\n",
    "            \n",
    "    else:\n",
    "        print(f'{p} folder already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee1066b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFolder('train', 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b93cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFolder('test', 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffade80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFolder('validation', 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d95077",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.resources import path\n",
    "image_data = ImageDataGenerator(rescale=1./255,validation_split = 0.2,zoom_range=(0.99,0.99),dtype=tf.float32)\n",
    "\n",
    "def preprocessingTrain(path):\n",
    "    \n",
    "    image = image_data.flow_from_directory(directory=path, \n",
    "                                           target_size=(150,150), \n",
    "                                           batch_size=256, \n",
    "                                           color_mode='rgb',\n",
    "                                           shuffle='True',\n",
    "                                           seed=123,\n",
    "                                           class_mode='binary', \n",
    "                                           subset='training',)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa73d7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingImages(path):\n",
    "    \n",
    "    image_data = ImageDataGenerator(rescale=1/255)\n",
    "    image = image_data.flow_from_directory(directory=path,\n",
    "                                           target_size = (150,150),\n",
    "                                           batch_size = 32,\n",
    "                                           class_mode = \"binary\",\n",
    "                                           )\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbedab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2568 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = './dataset/train'\n",
    "train_data= preprocessingTrain(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d6f6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 679 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = './dataset/validation'\n",
    "val_data= preprocessingImages(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9800959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 679 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "path = './dataset/test'\n",
    "test_data= preprocessingImages(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a650ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 150, 150, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 75, 75, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 75, 75, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 37, 37, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 87616)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               11214976  \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,243,457\n",
      "Trainable params: 11,243,073\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 00:01:23.944557: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(InputLayer(input_shape=(150,150,3)))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPool2D())\n",
    "model.add(Conv2D(filters=64,kernel_size=3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPool2D())\n",
    "\n",
    "\n",
    "model.add(Flatten()) #\n",
    "\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(0.001),loss = BinaryCrossentropy(),metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ada7ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model, to_file='model.png', show_shapes=True,\n",
    "    show_layer_names=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc09e611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in /Users/diganto/opt/anaconda3/envs/tf/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /Users/diganto/opt/anaconda3/envs/tf/lib/python3.9/site-packages (from pydot) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "%pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adb02680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping and model checkpoint\n",
    "from keras import utils, callbacks\n",
    "\n",
    "earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\", \n",
    "                                        mode=\"min\", \n",
    "                                        patience=5, \n",
    "                                        restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ca135e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.8\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m566.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.9.1 requires libclang>=13.0.0, which is not installed.\n",
      "tensorflow 2.9.1 requires tensorflow-io-gcs-filesystem>=0.23.1, which is not installed.\n",
      "tensorflow 2.9.1 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.8.0 which is incompatible.\n",
      "tensorflow 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.8.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install keras==2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "45d88872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h0/pjxkfbkd0jn4b1ngbzy6_d3c0000gn/T/ipykernel_7432/791066185.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_data,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0615 - accuracy: 0.9848WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 40s 4s/step - loss: 0.0615 - accuracy: 0.9848\n",
      "Epoch 2/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9903WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 42s 4s/step - loss: 0.0467 - accuracy: 0.9903\n",
      "Epoch 3/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9938WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.0376 - accuracy: 0.9938\n",
      "Epoch 4/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0401 - accuracy: 0.9918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.0401 - accuracy: 0.9918\n",
      "Epoch 5/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0752 - accuracy: 0.9759WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 45s 4s/step - loss: 0.0752 - accuracy: 0.9759\n",
      "Epoch 6/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1602 - accuracy: 0.9439WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.1602 - accuracy: 0.9439\n",
      "Epoch 7/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.1310 - accuracy: 0.9494WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.1310 - accuracy: 0.9494\n",
      "Epoch 8/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9774WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 46s 4s/step - loss: 0.0786 - accuracy: 0.9774\n",
      "Epoch 9/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0512 - accuracy: 0.9875WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 44s 4s/step - loss: 0.0512 - accuracy: 0.9875\n",
      "Epoch 10/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.0343 - accuracy: 0.9918\n",
      "Epoch 11/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9899WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 43s 4s/step - loss: 0.0399 - accuracy: 0.9899\n",
      "Epoch 12/12\n",
      "11/11 [==============================] - ETA: 0s - loss: 0.0759 - accuracy: 0.9751WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy\n",
      "11/11 [==============================] - 52s 5s/step - loss: 0.0759 - accuracy: 0.9751\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "history = model.fit_generator(train_data,\n",
    "                              verbose=1,\n",
    "                              callbacks = [earlystopping],\n",
    "                              epochs=12,\n",
    "                              validation_data=(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f9647f0aaaa87ff3502935c31d3b95edf29fd98ba2efc82941a1d3e9981ab4ca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
